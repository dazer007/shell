#nginx版本 nginx 1.14.x； 后面新项目使用： 1.16.x
#user  nobody;  #指定nginx用户，一般重新创建一个新用户给nginx
//user  root;  #指定nginx用户，需要指定，不指定，可能莫名的403；
# nginx 是一个7层的代理服务，支持对url的转发。对4层的转发，如端口需要使用haproxy， 或者 lvs。 最新的nginx也支持对4层代理了。

//worker_processes  4; ## worker_ processes 8; 工作进程:数目。根据硬件调整，通常等于CPU数量或者2倍于CPU。 ；cat /proc/cpuinfo | grep "cpu cores" | uniq

//error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

# pid 特指的是 主进程编号
#pid        logs/nginx.pid;


events {
  worker_connections  102400; ##这里原来是1024，现在后面多家两个0;每一个进程打开的最大连接数；  最大连接数 = worker_processes * worker_connections/4
  multi_accept on; #可以一次建立多个连接
  #use epoll;#IO多路复用方式
}


http {
  include mime.types;
  default_type  application/octet-stream;
  client_max_body_size 500m;# 设置1: 设置上传大小Sven
  server_tokens off; #设置2 隐藏http响应头里面显示nginx版本号，防止别人根据版本漏洞进行攻击

  ##设置3
  ###start 设置允许跨域，在这里设置了，就不用在java代码设置了：CrossOrigin ####
  ### 一般不要设置*，设置* 容易遭到跨站点 cros攻击，最好只设置运行 访问的外部网站
  add_header Access-Control-Allow-Origin *;
  add_header Access-Control-Allow-Headers X-Requested-With;
  add_header Access-Control-Allow-Methods GET, POST, PUT, DELETE, OPTIONS;
  ###end ###

  # 设置4: 获取客户端ip地址 Sven
  proxy_set_header X-Real-IP  $remote_addr;##获取客户端的真实ip,如果不加，就会代理服务器内网的ip
  proxy_set_header Host $host: $server_port;
  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;##防止客户端多层代理，获取不到真实的ip,Forwarded可以获取到 ip,代理ip1,代理ip2...，整个请求过程的所有ip
  proxy_set_header X-Forwarded-Scheme  $scheme; #增加一个header, 处理 SSL 认证之后，request.getScheme()获取不到https的问题记录
  proxy_set_header X-Forwarded-Proto   $scheme; #增加一个header, 处理 SSL 认证之后，request.getScheme()获取不到https的问题记录


  # 设置5: 速率限制 + 并发限制 https://www.cnblogs.com/biglittleant/p/8979915.html
  # http://nginx.org/en/docs/  搜索：limit
  #### limit_req_zone 用来限制单位时间内的请求数，即速率限制,采用的漏桶算法 "leaky bucket"。
  #### limit_req_conn 用来限制同一时间连接数，即并发限制。
  ### mylimit_req_name1 : 是自己给规则起的名称，可以随便起，
  ### $binary_remote_addr 是基于客户端ip,
  ### 如果超过限制：Response code: 429、Response message: Too Many Requests
  ### 如果超过限制：Response code: 503、Response message: Service Temporarily Unavailable;  服务器临不可用，服务器限流了
  ### _status 可以自定义超过限流的状态码
  limit_req_zone $binary_remote_addr zone = mylimit_req_name1:10m rate=800r/s;### 生成一个名字mylimit_req_name1的内存区域大小10MB，用来存储访问的频次信息。80QPS单个ip
  limit_req zone = mylimit_req_name1 burst=5 nodelay;##QBS大于阀值，请求排队个数（burst），排队的请求，nodelay（立即执行）
  limit_req_status 429;
  #---
  limit_conn_zone $binary_remote_addr zone = mylimit_conn_name1:10m;##生成一个名字叫做 mylimit_conn_name1的内存区域是10m的连接限制
  limit_conn mylimit_conn_name1 200;##单个ip限制连接数，这里20个
  limit_conn_status 428;

  #设置5：开发阶段，禁止缓存。把下面代码打开，每次请求都是最新的文件。
  #比如，可以自己写一个txt文件，使用微信打开，添加点内容。然后微信在打开，就可以看到效果。
  #注意，不要和  expires 1d; 冲突设置
  add_header Cache-Control no-cache;
  add_header Pragma no-cache;
  add_header Expires 0;

  ##设置6：504报错解决，完美解决Nginx 504 Gateway time-out; 系统有超过 300~500mb的视频，这了，超时时间调整为30分钟；
  ## 有时候，客户上传 比如 500MB的视频，或者导入 上万条的数据， 并且需要 业务处理。就非常慢，这里就调整大这个时间；
  proxy_connect_timeout  10s;#nginx跟后端服务器连接超时时间(代理连接超时)。【【代理服务器和后端的real server之间的超时】】，设置1s 或者 10s把。不能设置太大
  proxy_send_timeout  1800s;#后端服务器数据回传时间(代理发送超时)
  proxy_read_timeout  1800s;#连接成功后，后端服务器响应时间(代理接收超时)
  fastcgi_connect_timeout 1800s;#指定nginx与后端fastcgi server连接超时时间
  fastcgi_send_timeout 1800s;#指定nginx向后端传送请求超时时间（指已完成两次握手后向fastcgi传送请求超时时间）
  fastcgi_read_timeout 1800s;#指定nginx向后端传送响应超时时间（指已完成两次握手后向fastcgi传送响应超时时间）

  #与浏览器的长连接
  keepalive_timeout  1000;#长连接超时时间
  keepalive_requests 500;#500个请求以后，关闭长连接
  keepalive_disable msie6;#ie6禁用


  #    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
  #                      '$status $body_bytes_sent "$http_referer" '
  #                      '"$http_user_agent" "$http_x_forwarded_for"';
  #    access_log  logs/access.log  main;
  #    #默认写日志：打开文件写入关闭，max:缓存的文件描述符数量，inactive缓存时间，valid：检查时间间隔，min_uses：在inactive时间段内使用了多少次加入缓存
  #    open_log_file_cache max=200 inactive=20s valid=1m min_uses=2;

  #charset koi8-r;
  #access_log  logs/host.access.log  main;
  #生产环境关闭把，图书商城和bobo乐园项目，运行几个月10G的日志；tomcat logs/catelina.out也能达到10G;太费空间了
  # 生成环境一般 tomcat日志太多。或者nginx日志太大；
  #access_log logs/access.log main;
  access_log off;
  error_log /dev/null;


  #只有开启了sendfile，tcp_nopush才起作用
  #tcp_nodelay和tcp_nopush互斥，二者同时开启，nginx会： （1）确保数据包在发送给客户端之前是满的
  #（2）对于最后一个数据包，允许tcp立即发送，没有200ms的延迟
  #    tcp_nodelay on;
  #    sendfile       on;
  #    tcp_nopush     on;

  #开启GZIP压缩功能 压缩级别(gzip_comp_level)，1~10，数字越大压缩的越好，时间也越长，看心情随便改吧；但是越大不一定压缩一直增加
  gzip  on;
  gzip_min_length 2k;
  gzip_buffers 4 16k;
  gzip_comp_level 5;
  gzip_types text/plain application/x-javascript application/javascript text/css application/xml application/json text/javascript application/x-httpd-php image/jpeg image/gif image/png image/svg+xml;
  gzip_vary off;
  gzip_disable "MSIE [1-6]\.";
  gzip_static on; #如果有压缩好的 直接使用
  underscores_in_headers on;

  ##########################################
  ##缓存相关还没开启 proxy_cache_path
  ##########################################

  #Nginx 做负载均衡的几种轮询策略
  #ip_hash;每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
  #ip_hash: ❗️❗️❗️问题，可能一台服务器挂掉了，就 部分用户一直访问不了的； 建议使用redis解决session问题；不推荐使用
  #RR; 默认 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
  #weight和访问比率成正比，用于后端服务器性能不均的情况。
  #server 192.168.1.10 weight=1;
  upstream tomcat {
    #ip_hash;
    server 127.0.0.1: 8080 weight=2;
    # server 127.0.0.1:8081 weight=1 max_fails=3 fail_timeout=20s;## Nginx负载均衡配置fail_timeout https://segmentfault.com/q/1010000013600965
    keepalive 2000;
  }

  ###强制访问让http访问重定向到htts$$$$$
  server {
    listen 80;
    server_name  ityun.ltd ;


    location / {
      root   html;
      index  index.html index.htm;
      proxy_pass http://tomcat;
    }
  }
}